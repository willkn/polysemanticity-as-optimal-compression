`torch_dtype` is deprecated! Use `dtype` instead!
/opt/miniconda3/lib/python3.13/site-packages/sae_lens/saes/sae.py:248: UserWarning: 
This SAE has non-empty model_from_pretrained_kwargs. 
For optimal performance, load the model like so:
model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)
  warnings.warn(
/Users/kevknott/will/research/ARA/projects/the-neural-codec/experiments/gpt2_neuron_alignment.py:28: DeprecationWarning: Unpacking SAE objects is deprecated. SAE.from_pretrained() now returns only the SAE object. Use SAE.from_pretrained_with_cfg_and_sparsity() to get the config dict and sparsity as well.
  sae, _, _ = SAE.from_pretrained(release=SAE_RELEASE, sae_id=SAE_ID, device=DEVICE)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
üöÄ Loading gpt2-small and SAE on mps...
Loaded pretrained model gpt2-small into HookedTransformer
üèãÔ∏è Training with Neuron Alignment Monitoring...
Training:   0%|          | 0/50 [00:00<?, ?it/s]Training:   2%|‚ñè         | 1/50 [00:41<33:29, 41.02s/it]Training:   4%|‚ñç         | 2/50 [00:41<13:36, 17.01s/it]Training:   6%|‚ñå         | 3/50 [00:41<07:20,  9.36s/it]Training:   8%|‚ñä         | 4/50 [00:41<04:25,  5.77s/it]Training:  10%|‚ñà         | 5/50 [00:42<02:50,  3.78s/it]Training:  12%|‚ñà‚ñè        | 6/50 [00:42<01:53,  2.59s/it]Training:  14%|‚ñà‚ñç        | 7/50 [00:42<01:18,  1.82s/it]Training:  16%|‚ñà‚ñå        | 8/50 [00:42<00:55,  1.33s/it]Training:  18%|‚ñà‚ñä        | 9/50 [00:43<00:40,  1.01it/s]Training:  20%|‚ñà‚ñà        | 10/50 [00:43<00:30,  1.30it/s]Training:  22%|‚ñà‚ñà‚ñè       | 11/50 [00:43<00:23,  1.64it/s]Training:  24%|‚ñà‚ñà‚ñç       | 12/50 [00:43<00:18,  2.00it/s]Training:  26%|‚ñà‚ñà‚ñå       | 13/50 [00:44<00:15,  2.33it/s]Training:  28%|‚ñà‚ñà‚ñä       | 14/50 [00:44<00:13,  2.64it/s]Training:  30%|‚ñà‚ñà‚ñà       | 15/50 [00:44<00:11,  2.92it/s]Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [00:44<00:10,  3.17it/s]Training:  34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [00:45<00:09,  3.32it/s]Training:  36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [00:45<00:09,  3.48it/s]Training:  38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [00:45<00:08,  3.60it/s]Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [00:45<00:08,  3.69it/s]Training:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [00:46<00:07,  3.72it/s]Training:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [00:46<00:07,  3.77it/s]Training:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [00:46<00:07,  3.78it/s]Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [00:46<00:06,  3.84it/s]Training:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [00:47<00:06,  3.84it/s]Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [00:47<00:06,  3.86it/s]Training:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [00:47<00:05,  3.86it/s]Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [00:47<00:05,  3.87it/s]Training:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [00:48<00:05,  3.84it/s]Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [00:48<00:05,  3.89it/s]Training:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [00:48<00:04,  3.88it/s]Training:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [00:48<00:04,  3.91it/s]Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [00:49<00:04,  3.85it/s]Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [00:49<00:04,  3.87it/s]Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [00:49<00:03,  3.86it/s]Training:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [00:50<00:03,  3.86it/s]Training:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [00:50<00:03,  3.88it/s]Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [00:50<00:03,  3.90it/s]Training:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [00:50<00:02,  3.87it/s]Training:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [00:51<00:02,  3.85it/s]Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [00:51<00:02,  3.86it/s]Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [00:51<00:02,  3.86it/s]Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [00:51<00:01,  3.88it/s]Training:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [00:52<00:01,  3.84it/s]Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [00:52<00:01,  3.83it/s]Training:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [00:52<00:01,  3.86it/s]Training:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [00:52<00:00,  3.86it/s]Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [00:53<00:00,  3.86it/s]Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [00:53<00:00,  3.86it/s]Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:53<00:00,  3.89it/s]Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:53<00:00,  1.07s/it]

üîç CALCULATING NEURON ALIGNMENT...
----------------------------------------
üìä NEURON ALIGNMENT RESULTS:
  Mean Max-Correlation: 0.2241
  Top Neuron Alignment: 0.9998
----------------------------------------
‚ö†Ô∏è LACK OF ALIGNMENT: The Squeezer found a valid but DIFFERENT compression.
